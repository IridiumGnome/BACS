---
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
---

## Student ID: 112077423

```{r message=FALSE}
library(ggplot2)
library(compstatslib)
library(data.table)
library(tidyr)
library(lsa)
library(readxl)
library(tidyverse)
library(psych)
```

```{r}
df <- read_excel('security_questions.xlsx', sheet = 2)
head(df)
```

## Question 1(a)

*Show a single visualization with scree plot of data, scree plot of simulated noise (use average eigenvalues of ≥ 100 noise samples), and a horizontal line showing the eigenvalue = 1 cutoff.*

```{r}
set.seed(64528409)

df_pca <- prcomp(df, scale.=TRUE)
# function to get eigenvalues from noise data
sim_noise_ev <- function(n, p) {
  noise <- data.frame(replicate(p, rnorm(n)))
  return(eigen(cor(noise))$values)
}
# generate noise data
evalues_noise <- replicate(100, sim_noise_ev(nrow(df), ncol(df)))
# get mean of each row
evalues_mean <- apply(evalues_noise, 1, mean)
# plot
screeplot(df_pca, type="lines", col='cornflowerblue', lwd=2)
lines(evalues_mean, type="b", col='darkgreen', lwd=2)
abline(h=1, col="red", lty='dotted', lwd=1.5)
```

## Question 1(b)

*How many dimensions would you retain if we used Parallel Analysis?*

In the Parallel Analysis we reatain PC when its ev of original data > ev of noise data. In this case, I'd retain only two dimensions.

## Question 2(a)

*Looking at the loadings of the first 3 principal components, to which components does each item seem to best belong?*

```{r}
df_principal <- principal(df, nfactor=18, rotate="none", scores=TRUE)
df_principal$loadings[,1:3]
```

Q4, Q12, and Q17 best belong to PC2 whereas the rest best belong to PC1.

## Question 2(b)

*How much of the total variance of the security dataset do the first 3 PCs capture?*

```{r}
df_principal$Structure
```

The cumulative variance of the first three principal components is 0.67.

## Question 2(c)

*Looking at commonality and uniqueness, which items are less than adequately explained by the first 3 principal components?*

```{r}
principal(df, nfactor=3, rotate="none", scores=TRUE)
```

Items that are less than adequately explained by the first 3 principal components: Q1, Q2, Q3, Q6, Q7, Q9, Q11, Q13, Q14, Q15, Q16, Q18. Communality is less than 0.7

## Question 2(d)

*How many measurement items share similar loadings between 2 or more components?*

```{r}
loadings <- round(df_principal$loadings[, 1:18], 3)
num <- 0
lst <- list()
for (i in 1:18) {
  for (j in 1:18) {
    diff <- abs(abs(loadings[i,]) - abs(loadings[i, j]))
    diff[j] <- 5
    lst <- append(lst, names(diff)[diff == 0])
  }
  lst <- unlist(lst, recursive = FALSE)
  if(length(unique(lst)) >= 2) num <- num + 1
  lst <- list()
}
print(paste(num, 'measurement items share similar loadings between 2 or more components'))
```

## Question 2(e)

*Can you interpret a ‘meaning’ behind the first principal component from the items that load best upon it?*

```{r}
tmp <- round(df_principal$loadings[,1], 2)
tmp[tmp > 0.8]
```

Q1 and Q4 are more related to confidentiality whereas Q14 is more related to the accuracy of the information.

## Question 3(a)

*Individually, does each rotated component (RC) explain the same, or different, amount of variance than the corresponding principal components (PCs)?*

```{r}
df_pca_rot <- principal(df, nfactor=3, rotate="varimax", scores=TRUE)
df_pca_rot
```

Each rotated component (RC) explain **different** amount of variance than the corresponding principal component.

## Question 3(b)

*Together, do the three rotated components explain the same, more, or less cumulative variance as the three principal components combined?*

Three rotated components explain the **same** cumulative variance as the three principal components combined.

## Question 3(c)

*Looking back at the items that shared similar loadings with multiple principal components (2d), do those items have more clearly differentiated loadings among rotated components?*

Rotated components are not principal Components. Therefore, we have different loadings.

## Question 3(d)

*Can you now more easily interpret the “meaning” of the 3 rotated components from the items that load best upon each of them?*

```{r}
tmp <- round(df_pca_rot$loadings[], 2)

for (i in 1:nrow(tmp)) {
  for (j in 1:ncol(tmp)) {
    if (tmp[i, j] > 0.7) {
      #cat("\033[31m", tmp[i, j], "\033[0m", "\t", sep='')  
      cat(tmp[i, j], 'x\t')
    } else {
      cat(tmp[i, j], "\t")  
    }
  }
  cat("\n") 
}
```

RC1 is more about personal information-related things. RC2 is about data transmission. RC3 is about providing transaction-related evidence.

## Question 3(e)

*If we reduced the number of extracted and rotated components to 2, does the meaning of our rotated components change?*

```{r}
df_pca_rot <- principal(df, nfactor=2, rotate="varimax", scores=TRUE)


tmp <- round(df_pca_rot$loadings[], 2)

for (i in 1:nrow(tmp)) {
  for (j in 1:ncol(tmp)) {
    if (tmp[i, j] > 0.7) {
      #cat("\033[31m", tmp[i, j], "\033[0m\t", sep='') 
      cat(tmp[i, j], 'x\t')
    } else {
      cat(tmp[i, j], "\t")  
    }
  }
  cat("\n") 
}
```

I think the meaning does change to an extent.

## Additional Question

*Looking back at all our results and analyses of this dataset (from this week and previous), how many components (1-3) do you believe we should extract and analyze to understand the security dataset? Feel free to suggest different answers for different purposes.*

I'd still retain only one dimension. I don't think the second component has a great value even if it passed the Parallel Analysis.
