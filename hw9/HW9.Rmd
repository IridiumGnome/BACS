---
output:
  pdf_document:
    latex_engine: xelatex
---

```{r message=FALSE}
library(compstatslib)
library(data.table)
library(tidyr)
library(dplyr)
library(car)
library(lsa)
```

## Question 1

```{r}
cars <- read.table("auto-data.txt", header=FALSE, na.strings = "?")

names(cars) <- c("mpg", "cylinders", "displacement", "horsepower", "weight", 
                 "acceleration", "model_year", "origin", "car_name")

cars_log <- with(cars, data.frame(log(mpg), log(cylinders), log(displacement), 
                                  log(horsepower), log(weight), log(acceleration), 
                                  model_year, origin))
head(cars_log)
```

**(a)**

```{r}
model <- lm(log.mpg. ~ factor(origin) + . - origin, data=cars_log)
summary(model)
```
(i) Every variable except cylinders and displacement have a significant effect on log.mpg. at 10% significance.

(ii) Horsepower now is significant at alpha=10% and has an effect on mpg. By performing log transform on both sides of regression, we get more linear relationships. I guess the log transform of horsepower had a better effect than on other previously insignificant variables.

(iii) Cylinders and displacement still have insignificant effects on mpg. As I mentioned earlier, the possible reason could be that log transform wasn't that useful on those variables.

**(b)**

```{r}
regr_wt <- lm(cars$mpg ~ cars$weight)
regr_wt_log <- lm(cars_log$log.mpg. ~ cars_log$log.weight.)
```

```{r}
par(mfrow=c(1,2))

plot(density(regr_wt$residuals), lwd=2, main='raw', cex.main=0.9)
plot(density(regr_wt_log$residuals), lwd=2, main='log-transformed', cex.main=0.9)
mtext('density plots of residuals', side=3, line=-2, outer=TRUE)
```

```{r}
par(mfrow=c(1,2))

plot(cars$weight, resid(regr_wt), col="red", main='raw', cex.main=0.9)
abline(h=0)
plot(cars_log$log.weight., resid(regr_wt_log), col='red', 
     main='log-transformed', cex.main=0.9)
abline(h=0)
mtext('scatterplot of weight vs. residuals', side=3, line=-2, outer=TRUE)
```

(iv) log-transformed residuals produce better and more normal distribution

```{r}
summary(regr_wt_log)
```

(v) 1% change in log.weight leads to ~1% decrease in log.mpg

(vi) 

```{r}
conf_int <- confint(regr_wt_log)
conf_int
```

The 95% confidence interval for the slope of log.weight. vs log.mpg. is -1.1 to approximately -1.

## Question 2

```{r}
regr_log <- lm(log.mpg. ~ log.cylinders. + log.displacement. + log.horsepower. +
                              log.weight. + log.acceleration. + model_year +
                              factor(origin), data=cars_log)

summary(regr_log)
```

**(a)**

```{r}
weight_regr <- lm(log.weight. ~ log.cylinders. + log.displacement. + log.horsepower. +
                               log.acceleration. + model_year +
                              factor(origin), data=cars_log)
r2_weight <- summary(weight_regr)$r.squared
vif_weight <- 1 / (1 - r2_weight)
cat('VIF of log.weight is', vif_weight, sep=' ')
```

**(b)**

```{r}
vif(regr_log)
```

```{r}
# eliminate log.displacement.
regr_log <- lm(log.mpg. ~ log.cylinders. + log.horsepower. +
                              log.weight. + log.acceleration. + model_year +
                              factor(origin), data=cars_log)

vif(regr_log)
```

```{r}
# eliminate log.horsepower.
regr_log <- lm(log.mpg. ~ log.cylinders. + log.weight. + 
               log.acceleration. + model_year +
               factor(origin), data=cars_log)

vif(regr_log)
```

```{r}
# eliminate log.cylinders. 
regr_log <- lm(log.mpg. ~ log.weight. + log.acceleration. + model_year +
               factor(origin), data=cars_log)

vif(regr_log)
```

```{r}
summary(regr_log)
```

In the final regression model we have log.weight., log.acceleration., model_year, and origin as independent variables. 

**(c)**

One variable that was previously significant is horsepower. A 1% change in horsepower led to a ~.28% decrease in log.mpg. I don't think by dropping horsepower we decreased the quality of the model, since log.weight. coef. increased. 

**(d)**

If an independent variable has no correlation with other independent variables, its VIF score would be 1. 

For VIF scores of 5 or higher, variables would need to be correlated at R-squared = 4/5 at least. To get VIF scores of 10 or higher, variables would need to be correlated at R-squared = 9/10 at least.

## Question 3

**(a)**

```{r}
origin_colors = c("blue", "darkgreen", "red")
with(cars_log, plot(log.weight., log.mpg., pch=origin, col=origin_colors[origin]))

cars_us <- subset(cars_log, origin==1)
wt_regr_us <- lm(log.mpg. ~ log.weight., data=cars_us)
abline(wt_regr_us, col=origin_colors[1], lwd=2)

cars_eu <- subset(cars_log, origin==2)
wt_regr_eu <- lm(cars_eu$log.mpg. ~ cars_eu$log.weight.)
abline(wt_regr_eu, col=origin_colors[2], lwd=2)

cars_jp <- subset(cars_log, origin==3)
wt_regr_jp <- lm(cars_jp$log.mpg. ~ cars_jp$log.weight.)
abline(wt_regr_jp, col=origin_colors[3], lwd=2)
```

**(b)**

I believe that cars from different origins appear to have similar in a sense weight vs. mpg relationships.